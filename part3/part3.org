* PART 3
- https://www.udacity.com/course/machine-learning-for-trading--ud501
** 03-01 - How Machine Learning is used at a hedge fund
Building models
*** The ML problem

x -> Model -> y

Observation -> Model -> Prediction

Data -> ML -> Model

*** What's X and Y

Future price or return are predictions

*** Supervised Regression Learning

Supervised
Provide examples of x and y

Regression
Numerical approximation or prediction

Learning
Training with data


- Linear regression (parametric)
  - Finds the parameters for a model

- K nearest neighbor (KNN) (instance based)
  - Instance based because the data is kept from the training and consulted

- Decision trees
  - Query goes through the tree. Each node is a question. Reach a leave which is the regression value which is returned

- Decision forests
  - Collections of trees

*** Robot navigation example

video

*** How it works with stock data

Go back into the historical data
Pick a Y and then an X which is say 5 days prior
Then move forward and capture each instance or data point and save

This can be your training data

X's can be muli-dimensional
They are called factors

*** Example at a fintech company

Lucena Research

- Select X1, S2, X3, ... predictive factors
- Select Y. What you are interested in predicting
- Time period, stock universe
- Train
  - Takes data and creates a model

*** Price forcasting demo

QuantDesk
Cloud-based application created by Lucena Research

Select Forecasting Options

Select Model
Model defaults -> Factors

Forecast -> 1 week
Lookback -> 3 months

*** Backtesting

Roll back time and test on historical data
Limit data to previous data
and see how the system performs predicting the next data

*** ML tool in use

Example from QuantDesk

*** Problems with regresssion

Regression based forecasing can be useful

Thoughs issues:

- Nosiy and uncertain
- Challenging to estimate confidence
- Holding time, allocation. How to decide


Another idea:
Policy learning / Reenforcement Learning
more later on this

*** Problem we will focus on

Period - 2009

Text over the period - 2010 and 2011

Generate orders.txt and push through your market simulator

** 03-02 - Regression
*** Introduction
Supervised Regresion Learnning

Numerical Model

*** Parametric Regression

Building a model that is built with a number of parameters

y = mx + b

m and b are parameters

linear regression, fitting data to a line

Can fit a polynomial to better fit
y = m2 * x^2 + mx + b

Can add more terms. x^3, etc

Data is used to build a model (formula)

*** K nearest neighbor

Data centric or Instance approach

Look at the data for nearest data points to answer a query

*** How to predict

Since we are trying to predict y (rain) at given x (change in pressure), using the mean of nearest observed y values makes sens

*** Kernel Regression

You can repeat the process for all of the data points and you'll have a fitted line

Methods:
- K nearest neighbor (KNN)
  - non-weighted

- Kernel Regression
  - weighted


Instance based, keep the data and it is consulted when you make a query

*** Quiz: Parametric vs non?

Yes, the cannon ball distance can be best estimated using a parametric model, as it follows a well-defined trajectory.

On the other hand, the behavior of honey bees can be hard to model mathematically. Therefore, a non-parametric approach would be more suitable.

If you can quess at an equation a parametric model might work. If you don't or the data doesn't appear to be equation based, try a non-parametric

Parameteric doesn't have to store the data but you need it to re-train or add data.
Training is slow, query is fast

Non-Parameteric
You need to store the data and adding data is eadiy
Training is fast but querying can be slow

*** Training and Testing

Features
Different indicators
Multiple features

Prices, output are Y

Training and Testing data need to be segmented apart

Out of sample testing

|----------+--------|
| Features | Prices |
|----------+--------|
|          |        |
| XTrain   | YTrain |
|----------+--------|
|          |        |
| XTest    | YTest  |
|----------+--------|


Train on older data and test on new data

*** Learning APIs

For linear regression:

learner = LinRegLearner()

learner.train(Xtrain, Ytrain)

y = learner.query(Xtest)

These y values will be compared with Ytest values

For KNN:

learner = KNNLearner(k=3)

learner.train(Xtrain, Ytrain)

y = learner.query(Xtest)

*** Example for linear regression

#+BEGIN_SRC python

class LinRegLearner::

    def __init__():
        pass

    def train(X, Y):
        # find m and b for y = mx + b
        self.m, self.b = favorite_linreg(X, Y)         # see scipy, numpy

    def query(X):
        y = self.m * X + self.b
        return y

#+END_SRC

- https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.linregress.html
- scipy.stats.linregress


- KNN should have the same interface so you can try either type easily


- http://www.kdnuggets.com/2016/01/implementing-your-own-knn-using-python.html
- https://ashokharnal.wordpress.com/tag/k-nearest-neighbor-classification-example-using-python/
- ...

** 03-03 - Assessing a learning algorithm
*** Overview

There are many algorithms other than linear regression and knn

*** A closer look at KNN solutions

If you plot results the line is ragged.

Model can't extrapolate
Horizontal lines before and after the data

*** What happens as K varies

K = 1 just goes from one value to another
K = N just goes to the mean

As K increases are we likely to overfit? No

K=1 overfits

*** What happens as D varies

For a parameteric model
D is the number of degrees

The higher the number of polynomials (d) then the more likely to overfit.

Yes, in this case, increasing d increases model complexity, and
results in our model trying to closely align with the given data
points.

D = 1 is a linear model, results in a line
D = 2 is a parabola 
D = 3 has a cubed component

*** Metric 1 RMS error

Root Mean Squared error

Error is the difference to the modeled line

RMSE = sqrt( sum( Ytest - Ypredict) ^ 2 / N )

*** In Sample vs Out of Sample

What is the out of sample?
Find the error while using the Test set

*** Quiz: Which is worse

You would expect out-of-sample error to be larger, since the model has not seen points from the test set.

*** Cross validation

|-------+-----|
| Train | 60% |
| Test  | 40% |
|-------+-----|


If not enough data
Split into multiple training sets and a single test set. Say do multiple trials where you move the test segment around

*** Roll forward cross validation

If training data is after the test data then we have looked into the future

Make sure the training data is always before the test data.

Use smaller sets and roll forward for each trial

*** Metric 2: correlation
Take XTest and YText to get YPredict

Then plot YTest and YPredict (Scatter Plot)
Is there an alignment

Measure this quantitative using correlation


numpy.corrcoef()

-1 -> 0 -> +1

*** Quiz: Correlation and RMS error

As RMS error increases, correlation goes down.

*** Overfitting

Degrees of freedom (d) (degrees of the polynomial)

Error is highest when d is the lowest
As you increase d and approach the number data points the error goes to 0

Done with Training data results in what is called 'in sample error'


If you plot the out of sample error it will decrease but will curve up
Where it curves/diverges is overfitting
- in sample is decreasing
- out of sample is increasing

*** Quiz: KNN overfitting

K from 1 to N

Error is the is the lowest when K is 1

-- 

When k = 1, the model fits the training data perfectly, therefore
in-sample error is low (ideally, zero).  Out-of-sample error can be
quite high.

As k increases, the model becomes more generalized, thus out-of-sample
error decreases at the cost of slightly increasing in-sample error.

After a certain point, the model becomes too general and starts
performing worse on both training and test data.

-- 

Overfitting happens earlier, lower k values

*** Quiz: A few other considerations

|------------------------+------------+-----|
|                        | Linear Reg | KNN |
|------------------------+------------+-----|
| Space for saving model | -          |     |
| Compute time to train  |            | -   |
| Compute time to query  | -          |     |
| Ease to add new data   |            | -   |
|------------------------+------------+-----|

** 03-04 Ensemble learners, bagging and boosting
*** Overview

1988 - "Can a set of weak learners be combined to create a stronger learner?" Kearns and Valiant . 
2006 - Netflix competition
2009 - The winning algorithm was a combination of learners, an ensemble

Ensemble learners

*** Ensemble learners

KNN                            - https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm
LinReg                         - https://en.wikipedia.org/wiki/Simple_linear_regression
Decision Tree                  - https://en.wikipedia.org/wiki/Decision_tree_learning
Support Vector Machine (SVM)   - https://en.wikipedia.org/wiki/Support_vector_machine


Take the mean of the answers of all the results


Why?
- less error
- less overfitting


Each has it's own bias so when you combine the biases are reduced

*** Quiz: How to build an ensemble

If we combine several models of different types (here parameterized
polynomials and non-parameterized kNN models), we can avoid being
biased by one approach.


This typically results in less overfitting, and thus better
predictions in the long run, especially on unseen data.

*** Bootstrap aggregating bagging

Same learner but train different subsets of the data (bags of data)

Collect/bag the data randomly

Random with replacement means it is ok to grab the same data value again

| n  | number of training instances in our original data |
| n! | number of instances we put in each bag            |
| m  | number of bags                                    |


Rule of thumb

Each bag is used to train a different model

In the video (around 02:06), the professor mentions that n’ should be
set to about 60% of n, the number of training instances. It is more
accurate to say that in most implementations, n’ = n. Because the
training data is sampled with replacement, about 60% of the instances
in each bag are unique.

*** Quiz: Overfitting

A 1NN model (kNN with k = 1) matches the training data exactly, thus
overfitting.

An ensemble of such learners trained on slightly different datasets
will at least be able to provide some generalization, and typically
less out-of-sample error.

*** Bagging example

Each run looks like it is overfitting
Taking the mean of all the runs looks much more smooth

*** Boosting

AdaBoost (Adaptive Boost)

Use the training data after building the model to test the model

Build the next bag of data using the test results to weigh the choosen data according the errors found during the test run

Now, test both bags, combine outputs to build a new bag

Repeat

https://en.wikipedia.org/wiki/AdaBoost

*** Quiz: Overfitation

As m increases, AdaBoost tries to assign more and more specific data
points to subsequent learners, trying to model all the difficult
examples.

Thus, compared to simple bagging, it may result in more overfitting.

*** Summary

Boosting and bagging
- Wrappers for exisitng methods
- Hidden inside the same API. Callers don't need to know
- Reduces error
- Reduces overfitage
** 03-05 - Reinforcement learning
*** Overview

Up until this point we've focused forcast price changes and we buy the stocks with the most predicited price change.

This ignores the certainty of the price change and it doesn't help us know when to exit the position

Next, 

Reinforement learners create policies which provide specific direction on which action to take



